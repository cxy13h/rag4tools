### **问题背景、难点与解决方案**
####  背景
在RAG系统中，直接从结构化文本（如JSON）中检索信息时，如果将整个工具文档作为一个切片，会导致粒度过粗，影响检索精度；而如果将工具分解为零散的切片，又会丢失上下文，导致检索结果不完整。

####  难题
核心难点在于如何平衡切片的粒度。既要保证每个切片包含独立的语义信息，又要在检索后高效地将零散的切片重新聚合为完整的工具文档，以提供准确、全面的上下文。

####  解决方案
采用**“智能切片 + 粗排/精排”**的两阶段RAG流程。粗排时使用HNSW模型快速检索，精排时使用BAAI/bge-reranker模型精确检索。

* 智能切片： 将工具文档分解为语义完整的原子切片，并附加如工具的唯一标识uuid等元数据。

* 粗排： 快速检索出大量相关的切片（Top N），通过其元数据即uuid进行去重，得到去重后的工具列表作为精排的候选工具列表。

* 精排： 对候选工具进行精确检索，最终选出Top K个完整工具作为最终结果。

### **Tools示例**

假设我们有一个包含三个工具的 JSON 文档，每个工具都有详细的描述和参数。

**`get_stock_price`**

```json
{
  "ToolName": "get_stock_price",
  "ToolDescription": "用于查询指定股票代码的实时价格。",
  "Args": [
    {"ArgName": "symbol", "ArgDescription": "股票类型，例如：AAPL、MSFT。"},
    {"ArgName": "id", "ArgDescription": "股票编号"}
  ]
}
```

**`get_weather`**

```json
{
  "ToolName": "get_weather",
  "ToolDescription": "查询指定城市当前的天气状况。",
  "Args": [
    {"ArgName": "city", "ArgDescription": "城市名称，例如：北京、New York。"}
  ]
}
```

**`search_web`**

```json
{
  "ToolName": "search_web",
  "ToolDescription": "一个通用的网络搜索工具，可以查询新闻和网页。",
  "Args": [
    {"ArgName": "query", "ArgDescription": "用户的搜索关键词。"}
  ]
}
```

-----

### **第一阶段：数据预处理**

这一步是系统的基石。
为了防止出现同名的工具不好区分，我们为每个工具分配一个唯一的id（uuid）作为元数据。 以id为key，对应JSON文档为Value存入Redis数据库中。
然后我们将上述所有JSON 文档切片、向量化，并存储在Redis向量数据库中，具体步骤如下：

**1. 按概览和参数维度进行切片**
我们将每个工具分解成多个小切片，并附加元数据：

  * **`get_stock_price` 的切片：**

      * **切片 1 (概览)**：
          * 内容：`{"ToolName": "get_stock_price", "ToolDescription": "用于查询指定股票代码的实时价格。"}`
          * 元数据：`uuid-1`
      * **切片 2 (参数)**：
          * 内容：`{"ArgName": "symbol", "ArgDescription": "股票代码，例如：AAPL、MSFT。"}`
          * 元数据：`uuid-1`
      * **切片 3 (参数)**：
          * 内容：`{"ArgName": "id", "ArgDescription": "股票编号"}`
          * 元数据：`uuid-1`

  * **`get_weather` 的切片：**

      * **切片 3 (概览)**：
          * 内容：`{"ToolName": "get_weather", "ToolDescription": "查询指定城市当前的天气状况。"}`
          * 元数据：`uuid-2`
      * **切片 4 (参数)**：
          * 内容：`{"ArgName": "city", "ArgDescription": "城市名称，例如：北京、New York。"}`
          * 元数据：`uuid-2`

  * **`search_web` 的切片：**

      * **切片 5 (概览)**：
          * 内容：`{"ToolName": "search_web", "ToolDescription": "一个通用的网络搜索工具..."}`
          * 元数据：`uuid-3`
      * **切片 6 (参数)**：
          * 内容：`{"ArgName": "query", "ArgDescription": "用户的搜索关键词。"}`
          * 元数据：`uuid-3`

**2. 向量化与存储**
所有切片的内容部分都被转换为向量，并连同元数据一起存储在向量数据库中（注意只有内容会被转换为向量，元数据是不需要转换为向量的，即索引只需要建立在内容上）。

-----

### **第二阶段：粗排（初步检索）**

这一步的目标是从海量数据中，快速筛选出与用户查询相关的**大候选项集**。

**用户查询**：“如何查看股票价格？”

**1. 初步检索**

  * 将用户查询向量化。
  * 在向量数据库中进行相似度搜索，检索出最相似的 **N 个切片**。假设我们设置 N=100，这里我们只展示其中最相关的几个。
  * **Top N 切片（部分）**：
      * **切片 A (rank 1)**：`get_stock_price` 参数切片（得分最高）
      * **切片 B (rank 2)**：`get_stock_price` 概览切片
      * **切片 C (rank 3)**：`search_web` 参数切片（因为“查看股票价格”可能通过搜索实现）
      * **切片 D (rank 4)**：`search_web` 概览切片

**2. 工具去重与粗略排序**

  * **工具去重**：根据Top N个切片的元数据即uuid进行去重，得到去重后的列表：`[uuid-1, uuid-3]`。
  * **计算粗排得分**：我们使用 `得分 = sum(1 / (rank + 1))` 进行计算。
      * `uuid-1` 即 `get_stock_price` 得分 = `1/(1+1) + 1/(2+1) = 0.5 + 0.33 = 0.83`
      * `uuid-3` 即 `search_web` 得分 = `1/(3+1) + 1/(4+1) = 0.25 + 0.2 = 0.45`
      * 由于先前有进行去重，所以排序后得到的工具数量可能少于N个，这里假设得到了M个工具（示例中得到了2个）。

-----

### **第三阶段：精排（ReRank）**

这一步在**大规模**的候选集上进行更精准的排序，以确保最终结果的质量。

**1. 准备精排输入**

  * **原始查询**：`“如何查看股票价格？”`
  * **候选集完整JSON内容**：根据粗排后得到的一系列uuid，我们从Redis数据库中提取所有相应的JSON内容，作为精排模型的输入。

**2. 执行精排模型**

  * 精排模型（如 BAAI/bge-reranker-large）会逐一评估**查询**与每个**候选JSON**的相关性。
  * **精排得分（部分）**：
      * 查询 vs. `get_stock_price` 的JSON内容：`0.98`（高相关）
      * 查询 vs. `search_web` 的JSON内容：`0.6`（中等相关）
    
**3. 工具最终排序**

  * **最终排名**：
      * rank1:  `get_stock_price` 最终得分 = `0.98`
      * rank2:  `search_web` 最终得分 = `0.6`
      * ...
      * rankM: ...

**4. 选取 Top K 工具与返回**

  * 假设最终我们想要的 Top K=2，那么系统会选择 `get_stock_price` 和 `search_web`。

  * **最终返回结果**：
    ```json
    [
      {
        "ToolName": "get_stock_price",
        "ToolDescription": "用于查询指定股票代码的实时价格。",
        "Args": [
          {"ArgName": "symbol", "ArgDescription": "股票代码，例如：AAPL、MSFT。"}
        ]
      },
      {
        "ToolName": "search_web",
        "ToolDescription": "一个通用的网络搜索工具，可以查询新闻和网页。",
        "Args": [
          {"ArgName": "query", "ArgDescription": "用户的搜索关键词。"}
        ]
      }
    ]
    ```

通过这种粗排和精排结合的流程，我们既保证了在海量数据中的检索效率，又确保了最终返回的工具与用户查询的**语义相关性最高**。

### **技术栈**
* RedisVL（一个基于Redis的向量检索数据库），可以通过创建索引来实现快速的向量检索，以下是建立索引的示例：
```python
    from redisvl.schema import IndexSchema
    from redis import Redis
    from redisvl.index import SearchIndex
    schema = IndexSchema.from_dict({
        "index": {
            "name": "tool_slices_index",
            "prefix": "tool_slices"
        },
        "fields": [
            {
                "name": "embedding",
                "type": "vector",
                "attrs": {
                    "algorithm": "hnsw",
                    "datatype": "float32",
                    "dims": 1024,
                    "distance_metric": "cosine",
                    "m_hnsw": 16,
                    "ef_construction": 200
                }
            }
        ]
    })
    # 连接Redis数据库，可参考.env配置文件
    index = SearchIndex(schema, redis_url="...")  

    # Create the index in Redis
    index.create()
```
在添加切片数据时，其Redis数据结构应该为HASH，其中Key为"tool_slices"，内容为键值对列表例如：

```python
    data = [
        {
            "embedding": [0.1, 0.2, ...],
            "uuid": "uuid-1"
        },
        {
            "embedding": [0.3, 0.4, ...],
            "uuid": "uuid-1"
        },
    ]
```
RedisVL还提供了检索方式
```python
    from redisvl.query import VectorQuery

    query = VectorQuery(
    vector=[0.16, -0.34, ...],
    vector_field_name="embedding",
    num_results=5
    )

    results = index.query(query)
```
* Embedding模型：使用OpenAI提供的模型，其api_key/base_url/model名称可参考.env配置文件，具体用法如下：

```python
    import os
    from openai import OpenAI

    client = OpenAI(
        api_key=os.getenv("EMBEDDING_API_KEY"),
        base_url=os.getenv("EMBEDDING_BASE_URL")
    )

    completion = client.embeddings.create(
        model=os.getenv("EMBEDDING_MODEL"),
        input=['风急天高猿啸哀', '渚清沙白鸟飞回', '无边落木萧萧下', '不尽长江滚滚来'], # 最多支持10行
        dimensions=1024,# 指定向量维度
        encoding_format="float"
    )
```
其返回值示例如下：
```json
  { 
    "data": [
      {
        "embedding": [
          0.0023064255,
          -0.009327292,
          .... 
          -0.0028842222,
        ],
        "index": 0,
        "object": "embedding"
      }
    ],
    "model":"text-embedding-v3",
    "object":"list",
    "usage":{"prompt_tokens":26,"total_tokens":26},
    "id":"f62c2ae7-0906-9758-ab34-47c5764f07e2"
  }
```

* 精排模型：使用BAAI/bge-reranker-large模型，该模型已集成在FlagEmbeddingReranker中，示例如下：

```python
    from llama_index.postprocessor.flag_embedding_reranker import FlagEmbeddingReranker
    from llama_index.schema import NodeWithScore, QueryBundle, TextNode
    
    reranker = FlagEmbeddingReranker(
        top_n=3,
        model="BAAI/bge-reranker-large",
        use_fp16=False
    )

    documents = [
        "粗排后工具1完整内容",
        "粗排后工具2完整内容",
        "粗排后工具3完整内容",
        "粗排后工具4完整内容"
    ]

    nodes = [NodeWithScore(node=TextNode(text=doc)) for doc in documents]
    query = "股票情况如何？"

    query_bundle = QueryBundle(query_str=query)
    ranked_nodes = reranker._postprocess_nodes(nodes, query_bundle)
    
    for node in ranked_nodes:
        print(node.node.get_content(), "-> Score:", node.score)


```

* 环境管理工具:uv
